{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayhd3/NSF-REU-2021/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvZ-d105LLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "baa64b55-b29b-49fa-e5f7-087ebbee2b31"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('Xtst.csv'):\n",
        "  !gdown --id 1wQDp91LC0PBJvJRBTLw1aW51-UN5JOm8\n",
        "if not os.path.exists('Ytr.csv'):\n",
        "  !gdown --id 1ZhPVjXlOttrYRjSRm_IUBZj-Bokswzbn\n",
        "if not os.path.exists('Ytst.csv'):\n",
        "  !gdown --id 10LE7A7yhNkPlk8Zv3dmBjFYwMW9ZKy9_\n",
        "if not os.path.exists('Xtr.csv'):\n",
        "  !gdown --id 1IUcv_OcLX1YKUB1Xw_lYiBK6bnyLxikS\n",
        "if not os.path.exists('cnn1d.zip'):\n",
        "  !curl --remote-name -H 'Accept: application/vnd.github.v3.raw' --location 'https://github.com/mayhd3/NSF-REU-2021/raw/main/cnn1d.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wQDp91LC0PBJvJRBTLw1aW51-UN5JOm8\n",
            "To: /content/Xtst.csv\n",
            "308MB [00:05, 52.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZhPVjXlOttrYRjSRm_IUBZj-Bokswzbn\n",
            "To: /content/Ytr.csv\n",
            "25.7MB [00:00, 50.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LE7A7yhNkPlk8Zv3dmBjFYwMW9ZKy9_\n",
            "To: /content/Ytst.csv\n",
            "6.42MB [00:00, 30.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IUcv_OcLX1YKUB1Xw_lYiBK6bnyLxikS\n",
            "To: /content/Xtr.csv\n",
            "1.23GB [00:17, 70.1MB/s]\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   134  100   134    0     0    401      0 --:--:-- --:--:-- --:--:--   401\n",
            "100 1232k  100 1232k    0     0  1457k      0 --:--:-- --:--:-- --:--:-- 10.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKcJ9_rYIpi5"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import preprocessing\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "Xtr = pd.read_csv(\"Xtr.csv\", sep=',', header=None)\n",
        "Xtst = pd.read_csv(\"Xtst.csv\", sep=',', header=None)\n",
        "Ytr = pd.read_csv(\"Ytr.csv\", sep=',', header=None)\n",
        "Ytst = pd.read_csv(\"Ytst.csv\", sep=',', header=None)\n",
        "\n",
        "def train_test_base_model(Xtr, Xtst, Ytr, Ytst):\n",
        "  scaler = preprocessing.StandardScaler().fit(Xtr)\n",
        "  xtr = scaler.transform(Xtr)  \n",
        "  xtst = scaler.transform(Xtst)  \n",
        "\n",
        "  xtr = xtr.reshape(xtr.shape[0],xtr.shape[1],1)\n",
        "  xtst = xtst.reshape(xtst.shape[0],xtst.shape[1],1)\n",
        "\n",
        "  print (\"Number of training samples is: \",xtr.shape[0])\n",
        "  print (\"Number of test samples is: \",xtst.shape[0])\n",
        "\n",
        "  num_classes = 2\n",
        "\n",
        "  ytr = to_categorical(Ytr, num_classes)\n",
        "  ytst = to_categorical(Ytst, num_classes)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(32, kernel_size=7, activation='relu', input_shape=xtr.shape[1:]))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))    \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "  model.fit(xtr, ytr, epochs=150, verbose=2, batch_size=128,validation_split=0.3)  #learning_rte\n",
        "  print(\"Evaluation of best performing model:\")\n",
        "  model.evaluate(xtst, ytst)\n",
        "  return model\n",
        "\n",
        "if not os.path.exists('cnn1d.zip'):\n",
        "  model = train_test_base_model(Xtr,Xtst,Ytr,Ytst)\n",
        "  model.save('cnn1d')\n",
        "  !zip -r cnn1d.zip cnn1d\n",
        "else:\n",
        "  if not os.path.exists('cnn1d'):\n",
        "    !unzip cnn1d.zip\n",
        "  model = load_model('cnn1d')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfYlZAxMom76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50440c4-122d-4be6-92e4-2064a1256b9e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def percentiles(x,y,p):\n",
        "# labels = np.argmax(y, axis=1)\n",
        "  bisect = [ np.compress(y == label, x, axis=0) for label in [0.0,1.0] ]\n",
        "  print(x.shape)\n",
        "  totals = [ np.sum(part, axis=1) for part in bisect ]\n",
        "  print([np.percentile(total, p) for total in totals])\n",
        "  return (y == 0.) & (np.sum(x, axis=1) < np.percentile(totals[0],p))\n",
        "    # [bisect[i][totals[i] < np.percentile(totals[i], p)] for i in [0,1]]\n",
        "\n",
        "Ytr_low = percentiles(Xtr.to_numpy(),Ytr.to_numpy().flatten(),10).astype(int)\n",
        "Ytst_low = percentiles(Xtst.to_numpy(),Ytst.to_numpy().flatten(),10).astype(int)\n",
        "\n",
        "discriminator = train_test_base_model(Xtr, Xtst, Ytr_low, Ytst_low)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1029085, 48)\n",
            "[5.958668296039206, 2.203336569764192]\n",
            "(256883, 48)\n",
            "[6.358757727843121, 2.561238887802642]\n",
            "Number of training samples is:  1029085\n",
            "Number of test samples is:  256883\n",
            "Epoch 1/150\n",
            "5628/5628 - 46s - loss: 0.1097 - accuracy: 0.9525 - val_loss: 0.1254 - val_accuracy: 0.9471\n",
            "Epoch 2/150\n",
            "5628/5628 - 43s - loss: 0.0877 - accuracy: 0.9622 - val_loss: 0.1278 - val_accuracy: 0.9549\n",
            "Epoch 3/150\n",
            "5628/5628 - 43s - loss: 0.0681 - accuracy: 0.9726 - val_loss: 0.1481 - val_accuracy: 0.9556\n",
            "Epoch 4/150\n",
            "5628/5628 - 43s - loss: 0.0590 - accuracy: 0.9766 - val_loss: 0.1511 - val_accuracy: 0.9560\n",
            "Epoch 5/150\n",
            "5628/5628 - 43s - loss: 0.0532 - accuracy: 0.9788 - val_loss: 0.1573 - val_accuracy: 0.9584\n",
            "Epoch 6/150\n",
            "5628/5628 - 42s - loss: 0.0496 - accuracy: 0.9802 - val_loss: 0.1817 - val_accuracy: 0.9575\n",
            "Epoch 7/150\n",
            "5628/5628 - 44s - loss: 0.0465 - accuracy: 0.9815 - val_loss: 0.1693 - val_accuracy: 0.9590\n",
            "Epoch 8/150\n",
            "5628/5628 - 44s - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.1619 - val_accuracy: 0.9587\n",
            "Epoch 9/150\n",
            "5628/5628 - 43s - loss: 0.0417 - accuracy: 0.9834 - val_loss: 0.2270 - val_accuracy: 0.9591\n",
            "Epoch 10/150\n",
            "5628/5628 - 43s - loss: 0.0398 - accuracy: 0.9840 - val_loss: 0.2213 - val_accuracy: 0.9572\n",
            "Epoch 11/150\n",
            "5628/5628 - 43s - loss: 0.0382 - accuracy: 0.9847 - val_loss: 0.2085 - val_accuracy: 0.9596\n",
            "Epoch 12/150\n",
            "5628/5628 - 42s - loss: 0.0369 - accuracy: 0.9853 - val_loss: 0.2405 - val_accuracy: 0.9561\n",
            "Epoch 13/150\n",
            "5628/5628 - 42s - loss: 0.0358 - accuracy: 0.9856 - val_loss: 0.2321 - val_accuracy: 0.9592\n",
            "Epoch 14/150\n",
            "5628/5628 - 42s - loss: 0.0344 - accuracy: 0.9862 - val_loss: 0.2968 - val_accuracy: 0.9571\n",
            "Epoch 15/150\n",
            "5628/5628 - 43s - loss: 0.0334 - accuracy: 0.9867 - val_loss: 0.2533 - val_accuracy: 0.9551\n",
            "Epoch 16/150\n",
            "5628/5628 - 43s - loss: 0.0326 - accuracy: 0.9870 - val_loss: 0.2920 - val_accuracy: 0.9564\n",
            "Epoch 17/150\n",
            "5628/5628 - 43s - loss: 0.0315 - accuracy: 0.9874 - val_loss: 0.2915 - val_accuracy: 0.9577\n",
            "Epoch 18/150\n",
            "5628/5628 - 43s - loss: 0.0305 - accuracy: 0.9880 - val_loss: 0.3104 - val_accuracy: 0.9583\n",
            "Epoch 19/150\n",
            "5628/5628 - 43s - loss: 0.0299 - accuracy: 0.9881 - val_loss: 0.3282 - val_accuracy: 0.9581\n",
            "Epoch 20/150\n",
            "5628/5628 - 43s - loss: 0.0291 - accuracy: 0.9884 - val_loss: 0.3041 - val_accuracy: 0.9579\n",
            "Epoch 21/150\n",
            "5628/5628 - 43s - loss: 0.0281 - accuracy: 0.9887 - val_loss: 0.2902 - val_accuracy: 0.9576\n",
            "Epoch 22/150\n",
            "5628/5628 - 48s - loss: 0.0282 - accuracy: 0.9888 - val_loss: 0.3351 - val_accuracy: 0.9582\n",
            "Epoch 23/150\n",
            "5628/5628 - 44s - loss: 0.0273 - accuracy: 0.9892 - val_loss: 0.3885 - val_accuracy: 0.9570\n",
            "Epoch 24/150\n",
            "5628/5628 - 43s - loss: 0.0265 - accuracy: 0.9895 - val_loss: 0.3627 - val_accuracy: 0.9578\n",
            "Epoch 25/150\n",
            "5628/5628 - 44s - loss: 0.0260 - accuracy: 0.9898 - val_loss: 0.3565 - val_accuracy: 0.9576\n",
            "Epoch 26/150\n",
            "5628/5628 - 44s - loss: 0.0259 - accuracy: 0.9897 - val_loss: 0.3356 - val_accuracy: 0.9586\n",
            "Epoch 27/150\n",
            "5628/5628 - 43s - loss: 0.0253 - accuracy: 0.9901 - val_loss: 0.3878 - val_accuracy: 0.9582\n",
            "Epoch 28/150\n",
            "5628/5628 - 43s - loss: 0.0250 - accuracy: 0.9901 - val_loss: 0.4136 - val_accuracy: 0.9550\n",
            "Epoch 29/150\n",
            "5628/5628 - 43s - loss: 0.0244 - accuracy: 0.9904 - val_loss: 0.3515 - val_accuracy: 0.9572\n",
            "Epoch 30/150\n",
            "5628/5628 - 43s - loss: 0.0238 - accuracy: 0.9906 - val_loss: 0.4105 - val_accuracy: 0.9570\n",
            "Epoch 31/150\n",
            "5628/5628 - 42s - loss: 0.0234 - accuracy: 0.9908 - val_loss: 0.4504 - val_accuracy: 0.9557\n",
            "Epoch 32/150\n",
            "5628/5628 - 43s - loss: 0.0229 - accuracy: 0.9910 - val_loss: 0.4416 - val_accuracy: 0.9565\n",
            "Epoch 33/150\n",
            "5628/5628 - 43s - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.4395 - val_accuracy: 0.9569\n",
            "Epoch 34/150\n",
            "5628/5628 - 44s - loss: 0.0226 - accuracy: 0.9912 - val_loss: 0.4471 - val_accuracy: 0.9563\n",
            "Epoch 35/150\n",
            "5628/5628 - 43s - loss: 0.0218 - accuracy: 0.9914 - val_loss: 0.4594 - val_accuracy: 0.9579\n",
            "Epoch 36/150\n",
            "5628/5628 - 44s - loss: 0.0215 - accuracy: 0.9916 - val_loss: 0.4468 - val_accuracy: 0.9553\n",
            "Epoch 37/150\n",
            "5628/5628 - 43s - loss: 0.0214 - accuracy: 0.9916 - val_loss: 0.5131 - val_accuracy: 0.9581\n",
            "Epoch 38/150\n",
            "5628/5628 - 43s - loss: 0.0210 - accuracy: 0.9918 - val_loss: 0.4895 - val_accuracy: 0.9525\n",
            "Epoch 39/150\n",
            "5628/5628 - 42s - loss: 0.0210 - accuracy: 0.9916 - val_loss: 0.5161 - val_accuracy: 0.9564\n",
            "Epoch 40/150\n",
            "5628/5628 - 44s - loss: 0.0207 - accuracy: 0.9920 - val_loss: 0.5448 - val_accuracy: 0.9554\n",
            "Epoch 41/150\n",
            "5628/5628 - 47s - loss: 0.0205 - accuracy: 0.9920 - val_loss: 0.4790 - val_accuracy: 0.9547\n",
            "Epoch 42/150\n",
            "5628/5628 - 43s - loss: 0.0200 - accuracy: 0.9922 - val_loss: 0.4907 - val_accuracy: 0.9572\n",
            "Epoch 43/150\n",
            "5628/5628 - 43s - loss: 0.0197 - accuracy: 0.9924 - val_loss: 0.5730 - val_accuracy: 0.9570\n",
            "Epoch 44/150\n",
            "5628/5628 - 43s - loss: 0.0196 - accuracy: 0.9924 - val_loss: 0.5925 - val_accuracy: 0.9570\n",
            "Epoch 45/150\n",
            "5628/5628 - 43s - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.5909 - val_accuracy: 0.9575\n",
            "Epoch 46/150\n",
            "5628/5628 - 43s - loss: 0.0194 - accuracy: 0.9925 - val_loss: 0.5780 - val_accuracy: 0.9555\n",
            "Epoch 47/150\n",
            "5628/5628 - 43s - loss: 0.0189 - accuracy: 0.9927 - val_loss: 0.5700 - val_accuracy: 0.9549\n",
            "Epoch 48/150\n",
            "5628/5628 - 47s - loss: 0.0192 - accuracy: 0.9926 - val_loss: 0.5878 - val_accuracy: 0.9556\n",
            "Epoch 49/150\n",
            "5628/5628 - 43s - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.5595 - val_accuracy: 0.9545\n",
            "Epoch 50/150\n",
            "5628/5628 - 46s - loss: 0.0184 - accuracy: 0.9929 - val_loss: 0.5728 - val_accuracy: 0.9562\n",
            "Epoch 51/150\n",
            "5628/5628 - 43s - loss: 0.0186 - accuracy: 0.9929 - val_loss: 0.5653 - val_accuracy: 0.9555\n",
            "Epoch 52/150\n",
            "5628/5628 - 47s - loss: 0.0180 - accuracy: 0.9931 - val_loss: 0.6006 - val_accuracy: 0.9579\n",
            "Epoch 53/150\n",
            "5628/5628 - 43s - loss: 0.0182 - accuracy: 0.9930 - val_loss: 0.6011 - val_accuracy: 0.9558\n",
            "Epoch 54/150\n",
            "5628/5628 - 43s - loss: 0.0177 - accuracy: 0.9930 - val_loss: 0.6013 - val_accuracy: 0.9568\n",
            "Epoch 55/150\n",
            "5628/5628 - 43s - loss: 0.0178 - accuracy: 0.9932 - val_loss: 0.6178 - val_accuracy: 0.9561\n",
            "Epoch 56/150\n",
            "5628/5628 - 43s - loss: 0.0174 - accuracy: 0.9932 - val_loss: 0.6428 - val_accuracy: 0.9561\n",
            "Epoch 57/150\n",
            "5628/5628 - 43s - loss: 0.0176 - accuracy: 0.9932 - val_loss: 0.6908 - val_accuracy: 0.9566\n",
            "Epoch 58/150\n",
            "5628/5628 - 43s - loss: 0.0170 - accuracy: 0.9934 - val_loss: 0.7109 - val_accuracy: 0.9569\n",
            "Epoch 59/150\n",
            "5628/5628 - 43s - loss: 0.0168 - accuracy: 0.9936 - val_loss: 0.6919 - val_accuracy: 0.9570\n",
            "Epoch 60/150\n",
            "5628/5628 - 43s - loss: 0.0168 - accuracy: 0.9935 - val_loss: 0.6456 - val_accuracy: 0.9558\n",
            "Epoch 61/150\n",
            "5628/5628 - 42s - loss: 0.0170 - accuracy: 0.9936 - val_loss: 0.7346 - val_accuracy: 0.9559\n",
            "Epoch 62/150\n",
            "5628/5628 - 42s - loss: 0.0164 - accuracy: 0.9937 - val_loss: 0.7093 - val_accuracy: 0.9559\n",
            "Epoch 63/150\n",
            "5628/5628 - 42s - loss: 0.0165 - accuracy: 0.9937 - val_loss: 0.6541 - val_accuracy: 0.9567\n",
            "Epoch 64/150\n",
            "5628/5628 - 47s - loss: 0.0162 - accuracy: 0.9938 - val_loss: 0.6991 - val_accuracy: 0.9563\n",
            "Epoch 65/150\n",
            "5628/5628 - 43s - loss: 0.0157 - accuracy: 0.9939 - val_loss: 0.7262 - val_accuracy: 0.9562\n",
            "Epoch 66/150\n",
            "5628/5628 - 42s - loss: 0.0165 - accuracy: 0.9936 - val_loss: 0.6276 - val_accuracy: 0.9568\n",
            "Epoch 67/150\n",
            "5628/5628 - 42s - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.6971 - val_accuracy: 0.9558\n",
            "Epoch 68/150\n",
            "5628/5628 - 47s - loss: 0.0160 - accuracy: 0.9939 - val_loss: 0.7189 - val_accuracy: 0.9555\n",
            "Epoch 69/150\n",
            "5628/5628 - 47s - loss: 0.0156 - accuracy: 0.9939 - val_loss: 0.6963 - val_accuracy: 0.9561\n",
            "Epoch 70/150\n",
            "5628/5628 - 43s - loss: 0.0157 - accuracy: 0.9941 - val_loss: 0.6787 - val_accuracy: 0.9575\n",
            "Epoch 71/150\n",
            "5628/5628 - 44s - loss: 0.0154 - accuracy: 0.9941 - val_loss: 0.6949 - val_accuracy: 0.9561\n",
            "Epoch 72/150\n",
            "5628/5628 - 43s - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.7517 - val_accuracy: 0.9558\n",
            "Epoch 73/150\n",
            "5628/5628 - 43s - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.7845 - val_accuracy: 0.9568\n",
            "Epoch 74/150\n",
            "5628/5628 - 43s - loss: 0.0154 - accuracy: 0.9942 - val_loss: 0.7614 - val_accuracy: 0.9540\n",
            "Epoch 75/150\n",
            "5628/5628 - 43s - loss: 0.0149 - accuracy: 0.9943 - val_loss: 0.7918 - val_accuracy: 0.9564\n",
            "Epoch 76/150\n",
            "5628/5628 - 42s - loss: 0.0150 - accuracy: 0.9942 - val_loss: 0.7994 - val_accuracy: 0.9562\n",
            "Epoch 77/150\n",
            "5628/5628 - 42s - loss: 0.0152 - accuracy: 0.9943 - val_loss: 0.8823 - val_accuracy: 0.9567\n",
            "Epoch 78/150\n",
            "5628/5628 - 42s - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.7635 - val_accuracy: 0.9557\n",
            "Epoch 79/150\n",
            "5628/5628 - 43s - loss: 0.0146 - accuracy: 0.9945 - val_loss: 0.7701 - val_accuracy: 0.9573\n",
            "Epoch 80/150\n",
            "5628/5628 - 46s - loss: 0.0145 - accuracy: 0.9945 - val_loss: 0.8551 - val_accuracy: 0.9562\n",
            "Epoch 81/150\n",
            "5628/5628 - 42s - loss: 0.0148 - accuracy: 0.9944 - val_loss: 0.8142 - val_accuracy: 0.9547\n",
            "Epoch 82/150\n",
            "5628/5628 - 43s - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.8182 - val_accuracy: 0.9563\n",
            "Epoch 83/150\n",
            "5628/5628 - 43s - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.8764 - val_accuracy: 0.9565\n",
            "Epoch 84/150\n",
            "5628/5628 - 46s - loss: 0.0144 - accuracy: 0.9946 - val_loss: 0.7911 - val_accuracy: 0.9571\n",
            "Epoch 85/150\n",
            "5628/5628 - 42s - loss: 0.0149 - accuracy: 0.9944 - val_loss: 0.7758 - val_accuracy: 0.9558\n",
            "Epoch 86/150\n",
            "5628/5628 - 47s - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.8201 - val_accuracy: 0.9564\n",
            "Epoch 87/150\n",
            "5628/5628 - 43s - loss: 0.0139 - accuracy: 0.9947 - val_loss: 0.8498 - val_accuracy: 0.9563\n",
            "Epoch 88/150\n",
            "5628/5628 - 43s - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.7986 - val_accuracy: 0.9555\n",
            "Epoch 89/150\n",
            "5628/5628 - 43s - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.9103 - val_accuracy: 0.9569\n",
            "Epoch 90/150\n",
            "5628/5628 - 43s - loss: 0.0138 - accuracy: 0.9947 - val_loss: 0.9631 - val_accuracy: 0.9566\n",
            "Epoch 91/150\n",
            "5628/5628 - 43s - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.8619 - val_accuracy: 0.9562\n",
            "Epoch 92/150\n",
            "5628/5628 - 43s - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.9307 - val_accuracy: 0.9552\n",
            "Epoch 93/150\n",
            "5628/5628 - 43s - loss: 0.0135 - accuracy: 0.9949 - val_loss: 0.9146 - val_accuracy: 0.9565\n",
            "Epoch 94/150\n",
            "5628/5628 - 43s - loss: 0.0136 - accuracy: 0.9948 - val_loss: 0.9506 - val_accuracy: 0.9554\n",
            "Epoch 95/150\n",
            "5628/5628 - 42s - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.9840 - val_accuracy: 0.9568\n",
            "Epoch 96/150\n",
            "5628/5628 - 43s - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.8863 - val_accuracy: 0.9567\n",
            "Epoch 97/150\n",
            "5628/5628 - 43s - loss: 0.0132 - accuracy: 0.9951 - val_loss: 0.9095 - val_accuracy: 0.9548\n",
            "Epoch 98/150\n",
            "5628/5628 - 43s - loss: 0.0135 - accuracy: 0.9948 - val_loss: 0.9828 - val_accuracy: 0.9556\n",
            "Epoch 99/150\n",
            "5628/5628 - 42s - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.9737 - val_accuracy: 0.9562\n",
            "Epoch 100/150\n",
            "5628/5628 - 42s - loss: 0.0130 - accuracy: 0.9950 - val_loss: 0.9930 - val_accuracy: 0.9557\n",
            "Epoch 101/150\n",
            "5628/5628 - 43s - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.9464 - val_accuracy: 0.9561\n",
            "Epoch 102/150\n",
            "5628/5628 - 43s - loss: 0.0130 - accuracy: 0.9951 - val_loss: 1.0028 - val_accuracy: 0.9552\n",
            "Epoch 103/150\n",
            "5628/5628 - 46s - loss: 0.0130 - accuracy: 0.9951 - val_loss: 1.0127 - val_accuracy: 0.9545\n",
            "Epoch 104/150\n",
            "5628/5628 - 42s - loss: 0.0131 - accuracy: 0.9951 - val_loss: 1.0058 - val_accuracy: 0.9540\n",
            "Epoch 105/150\n",
            "5628/5628 - 43s - loss: 0.0127 - accuracy: 0.9952 - val_loss: 1.0455 - val_accuracy: 0.9563\n",
            "Epoch 106/150\n",
            "5628/5628 - 42s - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.9847 - val_accuracy: 0.9565\n",
            "Epoch 107/150\n",
            "5628/5628 - 42s - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.9845 - val_accuracy: 0.9564\n",
            "Epoch 108/150\n",
            "5628/5628 - 42s - loss: 0.0128 - accuracy: 0.9951 - val_loss: 1.0269 - val_accuracy: 0.9555\n",
            "Epoch 109/150\n",
            "5628/5628 - 43s - loss: 0.0125 - accuracy: 0.9954 - val_loss: 1.1073 - val_accuracy: 0.9556\n",
            "Epoch 110/150\n",
            "5628/5628 - 43s - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.9974 - val_accuracy: 0.9570\n",
            "Epoch 111/150\n",
            "5628/5628 - 43s - loss: 0.0127 - accuracy: 0.9953 - val_loss: 1.1287 - val_accuracy: 0.9556\n",
            "Epoch 112/150\n",
            "5628/5628 - 42s - loss: 0.0128 - accuracy: 0.9952 - val_loss: 1.1202 - val_accuracy: 0.9563\n",
            "Epoch 113/150\n",
            "5628/5628 - 43s - loss: 0.0126 - accuracy: 0.9954 - val_loss: 1.0320 - val_accuracy: 0.9558\n",
            "Epoch 114/150\n",
            "5628/5628 - 43s - loss: 0.0128 - accuracy: 0.9952 - val_loss: 1.1161 - val_accuracy: 0.9564\n",
            "Epoch 115/150\n",
            "5628/5628 - 42s - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.9748 - val_accuracy: 0.9562\n",
            "Epoch 116/150\n",
            "5628/5628 - 43s - loss: 0.0120 - accuracy: 0.9955 - val_loss: 1.1657 - val_accuracy: 0.9552\n",
            "Epoch 117/150\n",
            "5628/5628 - 43s - loss: 0.0123 - accuracy: 0.9954 - val_loss: 0.9079 - val_accuracy: 0.9550\n",
            "Epoch 118/150\n",
            "5628/5628 - 42s - loss: 0.0122 - accuracy: 0.9955 - val_loss: 1.1715 - val_accuracy: 0.9559\n",
            "Epoch 119/150\n",
            "5628/5628 - 46s - loss: 0.0122 - accuracy: 0.9955 - val_loss: 1.1036 - val_accuracy: 0.9561\n",
            "Epoch 120/150\n",
            "5628/5628 - 42s - loss: 0.0124 - accuracy: 0.9954 - val_loss: 1.1486 - val_accuracy: 0.9557\n",
            "Epoch 121/150\n",
            "5628/5628 - 43s - loss: 0.0125 - accuracy: 0.9953 - val_loss: 1.1738 - val_accuracy: 0.9566\n",
            "Epoch 122/150\n",
            "5628/5628 - 47s - loss: 0.0123 - accuracy: 0.9955 - val_loss: 1.0240 - val_accuracy: 0.9560\n",
            "Epoch 123/150\n",
            "5628/5628 - 43s - loss: 0.0118 - accuracy: 0.9956 - val_loss: 1.2197 - val_accuracy: 0.9554\n",
            "Epoch 124/150\n",
            "5628/5628 - 43s - loss: 0.0115 - accuracy: 0.9956 - val_loss: 1.1539 - val_accuracy: 0.9560\n",
            "Epoch 125/150\n",
            "5628/5628 - 47s - loss: 0.0121 - accuracy: 0.9955 - val_loss: 1.1676 - val_accuracy: 0.9568\n",
            "Epoch 126/150\n",
            "5628/5628 - 43s - loss: 0.0120 - accuracy: 0.9955 - val_loss: 1.1122 - val_accuracy: 0.9566\n",
            "Epoch 127/150\n",
            "5628/5628 - 43s - loss: 0.0117 - accuracy: 0.9955 - val_loss: 1.1340 - val_accuracy: 0.9561\n",
            "Epoch 128/150\n",
            "5628/5628 - 42s - loss: 0.0119 - accuracy: 0.9955 - val_loss: 1.0808 - val_accuracy: 0.9566\n",
            "Epoch 129/150\n",
            "5628/5628 - 42s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 1.1200 - val_accuracy: 0.9562\n",
            "Epoch 130/150\n",
            "5628/5628 - 43s - loss: 0.0122 - accuracy: 0.9956 - val_loss: 1.2136 - val_accuracy: 0.9542\n",
            "Epoch 131/150\n",
            "5628/5628 - 43s - loss: 0.0115 - accuracy: 0.9956 - val_loss: 1.2046 - val_accuracy: 0.9565\n",
            "Epoch 132/150\n",
            "5628/5628 - 43s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 1.0939 - val_accuracy: 0.9562\n",
            "Epoch 133/150\n",
            "5628/5628 - 43s - loss: 0.0116 - accuracy: 0.9957 - val_loss: 1.2102 - val_accuracy: 0.9557\n",
            "Epoch 134/150\n",
            "5628/5628 - 42s - loss: 0.0114 - accuracy: 0.9958 - val_loss: 1.2267 - val_accuracy: 0.9564\n",
            "Epoch 135/150\n",
            "5628/5628 - 42s - loss: 0.0116 - accuracy: 0.9956 - val_loss: 1.1931 - val_accuracy: 0.9561\n",
            "Epoch 136/150\n",
            "5628/5628 - 42s - loss: 0.0114 - accuracy: 0.9957 - val_loss: 1.2351 - val_accuracy: 0.9564\n",
            "Epoch 137/150\n",
            "5628/5628 - 42s - loss: 0.0112 - accuracy: 0.9957 - val_loss: 1.2503 - val_accuracy: 0.9555\n",
            "Epoch 138/150\n",
            "5628/5628 - 42s - loss: 0.0111 - accuracy: 0.9958 - val_loss: 1.2348 - val_accuracy: 0.9565\n",
            "Epoch 139/150\n",
            "5628/5628 - 43s - loss: 0.0114 - accuracy: 0.9958 - val_loss: 1.1092 - val_accuracy: 0.9551\n",
            "Epoch 140/150\n",
            "5628/5628 - 43s - loss: 0.0109 - accuracy: 0.9959 - val_loss: 1.1763 - val_accuracy: 0.9564\n",
            "Epoch 141/150\n",
            "5628/5628 - 42s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 1.2451 - val_accuracy: 0.9551\n",
            "Epoch 142/150\n",
            "5628/5628 - 47s - loss: 0.0113 - accuracy: 0.9958 - val_loss: 1.0921 - val_accuracy: 0.9562\n",
            "Epoch 143/150\n",
            "5628/5628 - 43s - loss: 0.0110 - accuracy: 0.9959 - val_loss: 1.2977 - val_accuracy: 0.9542\n",
            "Epoch 144/150\n",
            "5628/5628 - 46s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 1.3065 - val_accuracy: 0.9560\n",
            "Epoch 145/150\n",
            "5628/5628 - 43s - loss: 0.0106 - accuracy: 0.9960 - val_loss: 1.2464 - val_accuracy: 0.9560\n",
            "Epoch 146/150\n",
            "5628/5628 - 43s - loss: 0.0113 - accuracy: 0.9959 - val_loss: 1.2192 - val_accuracy: 0.9559\n",
            "Epoch 147/150\n",
            "5628/5628 - 43s - loss: 0.0108 - accuracy: 0.9960 - val_loss: 1.1944 - val_accuracy: 0.9547\n",
            "Epoch 148/150\n",
            "5628/5628 - 43s - loss: 0.0112 - accuracy: 0.9958 - val_loss: 1.2889 - val_accuracy: 0.9559\n",
            "Epoch 149/150\n",
            "5628/5628 - 43s - loss: 0.0113 - accuracy: 0.9959 - val_loss: 1.1837 - val_accuracy: 0.9548\n",
            "Epoch 150/150\n",
            "5628/5628 - 43s - loss: 0.0108 - accuracy: 0.9960 - val_loss: 1.3252 - val_accuracy: 0.9546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK6FzL0byG-8",
        "outputId": "6d96707c-ac7a-456c-b951-fa7872918dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discriminator.save('discriminator')\n",
        "!zip -r discriminator.zip cnn1d"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: discriminator/assets\n",
            "  adding: cnn1d/ (stored 0%)\n",
            "  adding: cnn1d/variables/ (stored 0%)\n",
            "  adding: cnn1d/variables/variables.data-00000-of-00001 (deflated 14%)\n",
            "  adding: cnn1d/variables/variables.index (deflated 64%)\n",
            "  adding: cnn1d/saved_model.pb (deflated 88%)\n",
            "  adding: cnn1d/assets/ (stored 0%)\n",
            "  adding: cnn1d/keras_metadata.pb (deflated 89%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ-6s2n6-yxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a297aa60-a79e-4f50-bbba-0b18206fb5df"
      },
      "source": [
        "try:\n",
        "  from art.attacks.evasion import FastGradientMethod, Wasserstein\n",
        "  from art.estimators.classification import TensorFlowV2Classifier\n",
        "except ImportError:\n",
        "  import sys\n",
        "  !{sys.executable} -m pip install adversarial-robustness-toolbox[Keras]\n",
        "  from art.attacks.evasion import FastGradientMethod, Wasserstein\n",
        "  from art.estimators.classification import TensorFlowV2Classifier\n",
        "import tensorflow as tf\n",
        "\n",
        "# Train the ART classifier\n",
        "\n",
        "classifier = TensorFlowV2Classifier(\n",
        "    model=model,\n",
        "    nb_classes=2,\n",
        "    input_shape=xtr.shape,\n",
        "    loss_object=tf.keras.losses.CategoricalCrossentropy(\n",
        "      from_logits=False,\n",
        "#      label_smoothing=0,\n",
        "#      axis=-1,\n",
        "#      reduction=\"auto\",\n",
        "      name=\"categorical_crossentropy\"\n",
        "  )\n",
        ")\n",
        "predictions = classifier.predict(xtst)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(ytst, axis=1)) / len(ytst)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "xtst_adv = attack.generate(x=xtst)\n",
        "\n",
        "# Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(xtst_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(ytst, axis=1)) / len(ytst)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adversarial-robustness-toolbox[Keras]\n",
            "  Downloading adversarial_robustness_toolbox-1.7.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.15.0)\n",
            "Collecting numba~=0.53.1\n",
            "  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 20.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (57.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (4.41.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (2.4.3)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 82 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[Keras]) (1.0.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->adversarial-robustness-toolbox[Keras]) (1.5.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->adversarial-robustness-toolbox[Keras]) (3.13)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.7.1 llvmlite-0.36.0 numba-0.53.1\n",
            "Accuracy on benign test examples: 93.67416294577687%\n",
            "Accuracy on adversarial test examples: 66.1472343440399%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYTW_P-OX4hd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}