{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Welcome To Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayhd3/NSF-REU-2021/blob/main/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbvZ-d105LLW",
        "outputId": "baa64b55-b29b-49fa-e5f7-087ebbee2b31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('Xtst.csv'):\n",
        "  !gdown --id 1wQDp91LC0PBJvJRBTLw1aW51-UN5JOm8\n",
        "if not os.path.exists('Ytr.csv'):\n",
        "  !gdown --id 1ZhPVjXlOttrYRjSRm_IUBZj-Bokswzbn\n",
        "if not os.path.exists('Ytst.csv'):\n",
        "  !gdown --id 10LE7A7yhNkPlk8Zv3dmBjFYwMW9ZKy9_\n",
        "if not os.path.exists('Xtr.csv'):\n",
        "  !gdown --id 1IUcv_OcLX1YKUB1Xw_lYiBK6bnyLxikS\n",
        "if not os.path.exists('cnn1d.zip'):\n",
        "  !curl --remote-name -H 'Accept: application/vnd.github.v3.raw' --location 'https://github.com/mayhd3/NSF-REU-2021/raw/main/cnn1d.zip'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1wQDp91LC0PBJvJRBTLw1aW51-UN5JOm8\n",
            "To: /content/Xtst.csv\n",
            "308MB [00:05, 52.4MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ZhPVjXlOttrYRjSRm_IUBZj-Bokswzbn\n",
            "To: /content/Ytr.csv\n",
            "25.7MB [00:00, 50.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10LE7A7yhNkPlk8Zv3dmBjFYwMW9ZKy9_\n",
            "To: /content/Ytst.csv\n",
            "6.42MB [00:00, 30.1MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1IUcv_OcLX1YKUB1Xw_lYiBK6bnyLxikS\n",
            "To: /content/Xtr.csv\n",
            "1.23GB [00:17, 70.1MB/s]\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   134  100   134    0     0    401      0 --:--:-- --:--:-- --:--:--   401\n",
            "100 1232k  100 1232k    0     0  1457k      0 --:--:-- --:--:-- --:--:-- 10.3M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKcJ9_rYIpi5"
      },
      "source": [
        "import pandas as pd\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from keras.optimizers import Adam\n",
        "from sklearn import preprocessing\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "Xtr = pd.read_csv(\"Xtr.csv\", sep=',', header=None)\n",
        "Xtst = pd.read_csv(\"Xtst.csv\", sep=',', header=None)\n",
        "Ytr = pd.read_csv(\"Ytr.csv\", sep=',', header=None)\n",
        "Ytst = pd.read_csv(\"Ytst.csv\", sep=',', header=None)\n",
        "\n",
        "def train_test_base_model(Xtr, Xtst, Ytr, Ytst):\n",
        "  scaler = preprocessing.StandardScaler().fit(Xtr)\n",
        "  xtr = scaler.transform(Xtr)  \n",
        "  xtst = scaler.transform(Xtst)  \n",
        "\n",
        "  xtr = xtr.reshape(xtr.shape[0],xtr.shape[1],1)\n",
        "  xtst = xtst.reshape(xtst.shape[0],xtst.shape[1],1)\n",
        "\n",
        "  print (\"Number of training samples is: \",xtr.shape[0])\n",
        "  print (\"Number of test samples is: \",xtst.shape[0])\n",
        "\n",
        "  num_classes = 2\n",
        "\n",
        "  ytr = to_categorical(Ytr, num_classes)\n",
        "  ytst = to_categorical(Ytst, num_classes)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv1D(32, kernel_size=7, activation='relu', input_shape=xtr.shape[1:]))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(num_classes, activation='softmax'))    \n",
        "  model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "  model.fit(xtr, ytr, epochs=150, verbose=2, batch_size=128,validation_split=0.3)  #learning_rte\n",
        "  print(\"Evaluation of best performing model:\")\n",
        "  model.evaluate(xtst, ytst)\n",
        "  return model\n",
        "\n",
        "if not os.path.exists('cnn1d.zip'):\n",
        "  model = train_test_base_model(Xtr,Xtst,Ytr,Ytst)\n",
        "  model.save('cnn1d')\n",
        "  !zip -r cnn1d.zip cnn1d\n",
        "else:\n",
        "  if not os.path.exists('cnn1d'):\n",
        "    !unzip cnn1d.zip\n",
        "  model = load_model('cnn1d')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfYlZAxMom76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f50440c4-122d-4be6-92e4-2064a1256b9e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def percentiles(x,y,p):\n",
        "# labels = np.argmax(y, axis=1)\n",
        "  bisect = [ np.compress(y == label, x, axis=0) for label in [0.0,1.0] ]\n",
        "  print(x.shape)\n",
        "  totals = [ np.sum(part, axis=1) for part in bisect ]\n",
        "  print([np.percentile(total, p) for total in totals])\n",
        "  return (y == 0.) & (np.sum(x, axis=1) < np.percentile(totals[0],p))\n",
        "    # [bisect[i][totals[i] < np.percentile(totals[i], p)] for i in [0,1]]\n",
        "\n",
        "Ytr_low = percentiles(Xtr.to_numpy(),Ytr.to_numpy().flatten(),10).astype(int)\n",
        "Ytst_low = percentiles(Xtst.to_numpy(),Ytst.to_numpy().flatten(),10).astype(int)\n",
        "\n",
        "discriminator = train_test_base_model(Xtr, Xtst, Ytr_low, Ytst_low)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1029085, 48)\n",
            "[5.958668296039206, 2.203336569764192]\n",
            "(256883, 48)\n",
            "[6.358757727843121, 2.561238887802642]\n",
            "Number of training samples is:  1029085\n",
            "Number of test samples is:  256883\n",
            "Epoch 1/150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZ-6s2n6-yxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a297aa60-a79e-4f50-bbba-0b18206fb5df"
      },
      "source": [
        "try:\n",
        "  from art.attacks.evasion import FastGradientMethod, Wasserstein\n",
        "  from art.estimators.classification import TensorFlowV2Classifier\n",
        "except ImportError:\n",
        "  import sys\n",
        "  !{sys.executable} -m pip install adversarial-robustness-toolbox[Keras]\n",
        "  from art.attacks.evasion import FastGradientMethod, Wasserstein\n",
        "  from art.estimators.classification import TensorFlowV2Classifier\n",
        "import tensorflow as tf\n",
        "\n",
        "# Train the ART classifier\n",
        "\n",
        "classifier = TensorFlowV2Classifier(\n",
        "    model=model,\n",
        "    nb_classes=2,\n",
        "    input_shape=xtr.shape,\n",
        "    loss_object=tf.keras.losses.CategoricalCrossentropy(\n",
        "      from_logits=False,\n",
        "#      label_smoothing=0,\n",
        "#      axis=-1,\n",
        "#      reduction=\"auto\",\n",
        "      name=\"categorical_crossentropy\"\n",
        "  )\n",
        ")\n",
        "predictions = classifier.predict(xtst)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(ytst, axis=1)) / len(ytst)\n",
        "print(\"Accuracy on benign test examples: {}%\".format(accuracy * 100))\n",
        "\n",
        "# Generate adversarial test examples\n",
        "attack = FastGradientMethod(estimator=classifier, eps=0.2)\n",
        "xtst_adv = attack.generate(x=xtst)\n",
        "\n",
        "# Evaluate the ART classifier on adversarial test examples\n",
        "\n",
        "predictions = classifier.predict(xtst_adv)\n",
        "accuracy = np.sum(np.argmax(predictions, axis=1) == np.argmax(ytst, axis=1)) / len(ytst)\n",
        "print(\"Accuracy on adversarial test examples: {}%\".format(accuracy * 100))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting adversarial-robustness-toolbox[Keras]\n",
            "  Downloading adversarial_robustness_toolbox-1.7.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 4.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn<0.24.3,>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.15.0)\n",
            "Collecting numba~=0.53.1\n",
            "  Downloading numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 20.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (57.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (4.41.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (3.1.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from adversarial-robustness-toolbox[Keras]) (2.4.3)\n",
            "Collecting llvmlite<0.37,>=0.36.0rc1\n",
            "  Downloading llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 82 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn<0.24.3,>=0.22.2->adversarial-robustness-toolbox[Keras]) (1.0.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->adversarial-robustness-toolbox[Keras]) (1.5.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->adversarial-robustness-toolbox[Keras]) (3.13)\n",
            "Installing collected packages: llvmlite, numba, adversarial-robustness-toolbox\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "Successfully installed adversarial-robustness-toolbox-1.7.1 llvmlite-0.36.0 numba-0.53.1\n",
            "Accuracy on benign test examples: 93.67416294577687%\n",
            "Accuracy on adversarial test examples: 66.1472343440399%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYTW_P-OX4hd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}