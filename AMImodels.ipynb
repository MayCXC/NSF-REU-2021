{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMImodels.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxNqqSmhEMkh4PXZ45NST2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mayhd3/NSF-REU-2021/blob/main/AMImodels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1m5uTTP_xSq",
        "outputId": "72fafbf5-58b2-4e06-b1de-1e3790c25e2c"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "if not os.path.exists('full.zip'):\n",
        "  !curl --remote-name -H 'Accept: application/vnd.github.v3.raw' --location 'https://github.com/mayhd3/NSF-REU-2021/raw/main/full.zip'\n",
        "\n",
        "full = pd.read_csv('full.zip')\n",
        "full.columns = range(len(full.columns))\n",
        "print(full)\n",
        "\n",
        "# group dataset by customer\n",
        "groups = full.groupby(2)\n",
        "meters = [groups.get_group(group) for group in groups.groups]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79572, 51)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYQdiCRGQORX",
        "outputId": "25b20fa9-afec-4868-b4c3-5425c217249f"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPool2D, Dropout, Flatten\n",
        "from keras.utils import np_utils\n",
        "from scipy.signal import find_peaks\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# partition training and testing datasets\n",
        "def bisect_ratio(array, ratio):\n",
        "  return (\n",
        "    [array[i] for i in range(len(array)) if i%ratio == 0],\n",
        "    [array[i] for i in range(len(array)) if i%ratio != 0]\n",
        "  )\n",
        "\n",
        "def bhwc(twod):\n",
        "  return np.expand_dims(np.array(twod), axis=-1).astype('float32')\n",
        "\n",
        "X = [meter.iloc[:,5:].to_numpy().flatten() for meter in meters]\n",
        "y = [np_utils.to_categorical(min(meter.iloc[0,0],1), num_classes=2) for meter in meters]\n",
        "\n",
        "X_test, X_train = (bhwc(x) for x in bisect_ratio(X, 3))\n",
        "y_test, y_train = (np.array(yb) for yb in bisect_ratio(y, 3))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, kernel_size=7, activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))    \n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, epochs=52, verbose=2, batch_size=128,validation_split=0.3)\n",
        "print(model.evaluate(X_test, y_test))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "1/1 - 16s - loss: 3.2162 - accuracy: 0.2830 - val_loss: 951.7249 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/52\n",
            "1/1 - 1s - loss: 340.1325 - accuracy: 0.7170 - val_loss: 445.9047 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/52\n",
            "1/1 - 2s - loss: 158.0347 - accuracy: 0.7170 - val_loss: 133.8114 - val_accuracy: 1.0000\n",
            "Epoch 4/52\n",
            "1/1 - 1s - loss: 394.1600 - accuracy: 0.2830 - val_loss: 0.7126 - val_accuracy: 1.0000\n",
            "Epoch 5/52\n",
            "1/1 - 1s - loss: 200.8747 - accuracy: 0.2830 - val_loss: 292.5538 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/52\n",
            "1/1 - 1s - loss: 244.9329 - accuracy: 0.7170 - val_loss: 453.0124 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/52\n",
            "1/1 - 1s - loss: 155.7271 - accuracy: 0.7170 - val_loss: 505.0510 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/52\n",
            "1/1 - 1s - loss: 172.6947 - accuracy: 0.7170 - val_loss: 439.4602 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/52\n",
            "1/1 - 1s - loss: 148.2484 - accuracy: 0.7170 - val_loss: 297.5457 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/52\n",
            "1/1 - 1s - loss: 96.1788 - accuracy: 0.7170 - val_loss: 139.7104 - val_accuracy: 0.0870\n",
            "Epoch 11/52\n",
            "1/1 - 1s - loss: 68.4159 - accuracy: 0.7358 - val_loss: 54.1040 - val_accuracy: 0.4348\n",
            "Epoch 12/52\n",
            "1/1 - 1s - loss: 19.5961 - accuracy: 0.8208 - val_loss: 46.2459 - val_accuracy: 0.6739\n",
            "Epoch 13/52\n",
            "1/1 - 1s - loss: 61.7939 - accuracy: 0.7642 - val_loss: 66.6533 - val_accuracy: 0.4565\n",
            "Epoch 14/52\n",
            "1/1 - 2s - loss: 39.0087 - accuracy: 0.8113 - val_loss: 116.6923 - val_accuracy: 0.1304\n",
            "Epoch 15/52\n",
            "1/1 - 1s - loss: 26.3772 - accuracy: 0.7453 - val_loss: 135.0350 - val_accuracy: 0.1304\n",
            "Epoch 16/52\n",
            "1/1 - 1s - loss: 35.1299 - accuracy: 0.7453 - val_loss: 121.8224 - val_accuracy: 0.2609\n",
            "Epoch 17/52\n",
            "1/1 - 1s - loss: 43.0011 - accuracy: 0.7830 - val_loss: 106.3560 - val_accuracy: 0.3478\n",
            "Epoch 18/52\n",
            "1/1 - 1s - loss: 36.1728 - accuracy: 0.7925 - val_loss: 85.9806 - val_accuracy: 0.3696\n",
            "Epoch 19/52\n",
            "1/1 - 1s - loss: 15.7709 - accuracy: 0.8113 - val_loss: 63.7891 - val_accuracy: 0.4348\n",
            "Epoch 20/52\n",
            "1/1 - 1s - loss: 11.0544 - accuracy: 0.8396 - val_loss: 49.4195 - val_accuracy: 0.5652\n",
            "Epoch 21/52\n",
            "1/1 - 1s - loss: 22.7087 - accuracy: 0.8208 - val_loss: 40.3536 - val_accuracy: 0.5652\n",
            "Epoch 22/52\n",
            "1/1 - 1s - loss: 16.9187 - accuracy: 0.8113 - val_loss: 42.0801 - val_accuracy: 0.5435\n",
            "Epoch 23/52\n",
            "1/1 - 1s - loss: 7.1826 - accuracy: 0.8113 - val_loss: 62.8217 - val_accuracy: 0.4130\n",
            "Epoch 24/52\n",
            "1/1 - 1s - loss: 10.6091 - accuracy: 0.8396 - val_loss: 85.9990 - val_accuracy: 0.3478\n",
            "Epoch 25/52\n",
            "1/1 - 1s - loss: 13.7704 - accuracy: 0.8208 - val_loss: 101.3656 - val_accuracy: 0.2826\n",
            "Epoch 26/52\n",
            "1/1 - 1s - loss: 14.0996 - accuracy: 0.8208 - val_loss: 88.7816 - val_accuracy: 0.3261\n",
            "Epoch 27/52\n",
            "1/1 - 1s - loss: 9.6376 - accuracy: 0.8302 - val_loss: 55.5125 - val_accuracy: 0.4348\n",
            "Epoch 28/52\n",
            "1/1 - 1s - loss: 3.8100 - accuracy: 0.8491 - val_loss: 29.4918 - val_accuracy: 0.6087\n",
            "Epoch 29/52\n",
            "1/1 - 1s - loss: 10.0086 - accuracy: 0.8208 - val_loss: 30.2521 - val_accuracy: 0.6087\n",
            "Epoch 30/52\n",
            "1/1 - 1s - loss: 9.9666 - accuracy: 0.8208 - val_loss: 52.5086 - val_accuracy: 0.4565\n",
            "Epoch 31/52\n",
            "1/1 - 1s - loss: 4.4179 - accuracy: 0.8396 - val_loss: 77.4084 - val_accuracy: 0.3478\n",
            "Epoch 32/52\n",
            "1/1 - 1s - loss: 5.5427 - accuracy: 0.8396 - val_loss: 79.6291 - val_accuracy: 0.3478\n",
            "Epoch 33/52\n",
            "1/1 - 1s - loss: 6.4024 - accuracy: 0.8396 - val_loss: 65.3880 - val_accuracy: 0.3478\n",
            "Epoch 34/52\n",
            "1/1 - 1s - loss: 6.2416 - accuracy: 0.8774 - val_loss: 52.0521 - val_accuracy: 0.4348\n",
            "Epoch 35/52\n",
            "1/1 - 1s - loss: 3.1636 - accuracy: 0.8679 - val_loss: 46.7472 - val_accuracy: 0.4565\n",
            "Epoch 36/52\n",
            "1/1 - 1s - loss: 3.4693 - accuracy: 0.8491 - val_loss: 52.9975 - val_accuracy: 0.4348\n",
            "Epoch 37/52\n",
            "1/1 - 1s - loss: 5.8037 - accuracy: 0.8774 - val_loss: 56.8745 - val_accuracy: 0.3696\n",
            "Epoch 38/52\n",
            "1/1 - 1s - loss: 2.9272 - accuracy: 0.8962 - val_loss: 59.7902 - val_accuracy: 0.3478\n",
            "Epoch 39/52\n",
            "1/1 - 1s - loss: 3.0097 - accuracy: 0.9151 - val_loss: 61.8628 - val_accuracy: 0.3478\n",
            "Epoch 40/52\n",
            "1/1 - 1s - loss: 4.9092 - accuracy: 0.8868 - val_loss: 61.7618 - val_accuracy: 0.3478\n",
            "Epoch 41/52\n",
            "1/1 - 1s - loss: 2.3096 - accuracy: 0.8868 - val_loss: 58.0648 - val_accuracy: 0.3696\n",
            "Epoch 42/52\n",
            "1/1 - 1s - loss: 2.5752 - accuracy: 0.8962 - val_loss: 51.8910 - val_accuracy: 0.3913\n",
            "Epoch 43/52\n",
            "1/1 - 1s - loss: 3.5847 - accuracy: 0.8774 - val_loss: 46.3506 - val_accuracy: 0.4348\n",
            "Epoch 44/52\n",
            "1/1 - 1s - loss: 2.0774 - accuracy: 0.8679 - val_loss: 57.2634 - val_accuracy: 0.3696\n",
            "Epoch 45/52\n",
            "1/1 - 1s - loss: 2.3511 - accuracy: 0.9245 - val_loss: 67.5669 - val_accuracy: 0.3478\n",
            "Epoch 46/52\n",
            "1/1 - 1s - loss: 2.9366 - accuracy: 0.8491 - val_loss: 65.8469 - val_accuracy: 0.3478\n",
            "Epoch 47/52\n",
            "1/1 - 1s - loss: 1.9963 - accuracy: 0.8679 - val_loss: 48.1330 - val_accuracy: 0.4348\n",
            "Epoch 48/52\n",
            "1/1 - 1s - loss: 1.5156 - accuracy: 0.8868 - val_loss: 42.9935 - val_accuracy: 0.4565\n",
            "Epoch 49/52\n",
            "1/1 - 1s - loss: 2.5943 - accuracy: 0.8679 - val_loss: 54.9524 - val_accuracy: 0.3696\n",
            "Epoch 50/52\n",
            "1/1 - 1s - loss: 0.6877 - accuracy: 0.9434 - val_loss: 65.8034 - val_accuracy: 0.3478\n",
            "Epoch 51/52\n",
            "1/1 - 1s - loss: 1.8644 - accuracy: 0.8679 - val_loss: 57.8284 - val_accuracy: 0.3696\n",
            "Epoch 52/52\n",
            "1/1 - 1s - loss: 1.5006 - accuracy: 0.9340 - val_loss: 49.0702 - val_accuracy: 0.3913\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 38.6617 - accuracy: 0.5789\n",
            "[38.66173553466797, 0.5789473652839661]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXk-FDqTASVq",
        "outputId": "9080fac5-7dfd-42f9-8299-6580ae101b91"
      },
      "source": [
        "# cnn input is a 2D array of semi hourly consumption by week\n",
        "X0 = [meter.iloc[:,5:].to_numpy() for meter in meters]\n",
        "y0 = [{0: [0,0], 1: [0,1], 2:[1,0], 3:[1,1]}[meter.iloc[0,0]] for meter in meters]\n",
        "\n",
        "X0_test, X0_train = bisect_ratio(X0, 3) # (bhwc(X) for X in )\n",
        "X0_test = bhwc(X0_test)\n",
        "X0_train = bhwc(X0_train)\n",
        "y0_test, y0_train = (np.array(y) for y in bisect_ratio(y0, 3))\n",
        "\n",
        "# cnn structure is (conv -> pool) x3 -> flatten -> dense -> dropout -> dense -> softmax\n",
        "cnn = Sequential()\n",
        "cnn.add(Conv2D(32, (3,3), input_shape=X0_train.shape[1:], activation='relu'))\n",
        "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
        "cnn.add(Conv2D(64,(3,3),activation='relu'))\n",
        "cnn.add(MaxPool2D(pool_size=(2,2)))\n",
        "cnn.add(Conv2D(128,(5,5),activation='relu'))\n",
        "cnn.add(MaxPool2D(pool_size=(4,4)))\n",
        "cnn.add(Flatten())\n",
        "cnn.add(Dense(128, activation='relu'))\n",
        "cnn.add(Dropout(0.0125))\n",
        "cnn.add(Dense(64, activation='relu'))\n",
        "cnn.add(Dense(32, activation='relu'))\n",
        "cnn.add(Dense(2, activation='softmax'))\n",
        "\n",
        "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "cnn.fit(X0_train, y0_train, epochs=52, batch_size=38)\n",
        "print(cnn.evaluate(X0_test, y0_test))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/52\n",
            "4/4 [==============================] - 6s 964ms/step - loss: 2.0686 - accuracy: 0.5509\n",
            "Epoch 2/52\n",
            "4/4 [==============================] - 4s 956ms/step - loss: 0.9578 - accuracy: 0.6588\n",
            "Epoch 3/52\n",
            "4/4 [==============================] - 4s 950ms/step - loss: 2.1577 - accuracy: 0.5640\n",
            "Epoch 4/52\n",
            "4/4 [==============================] - 4s 930ms/step - loss: 4.9572 - accuracy: 0.6237\n",
            "Epoch 5/52\n",
            "4/4 [==============================] - 4s 931ms/step - loss: 13.4944 - accuracy: 0.7307\n",
            "Epoch 6/52\n",
            "4/4 [==============================] - 4s 935ms/step - loss: 25.1224 - accuracy: 0.7325\n",
            "Epoch 7/52\n",
            "4/4 [==============================] - 4s 935ms/step - loss: 94.5141 - accuracy: 0.7772\n",
            "Epoch 8/52\n",
            "4/4 [==============================] - 4s 961ms/step - loss: 101.0329 - accuracy: 0.6868\n",
            "Epoch 9/52\n",
            "4/4 [==============================] - 4s 959ms/step - loss: 324.6811 - accuracy: 0.6351\n",
            "Epoch 10/52\n",
            "4/4 [==============================] - 4s 942ms/step - loss: 551.0796 - accuracy: 0.7018\n",
            "Epoch 11/52\n",
            "4/4 [==============================] - 4s 946ms/step - loss: 803.7384 - accuracy: 0.5842\n",
            "Epoch 12/52\n",
            "4/4 [==============================] - 4s 956ms/step - loss: 3829.1744 - accuracy: 0.6798\n",
            "Epoch 13/52\n",
            "4/4 [==============================] - 4s 937ms/step - loss: 4056.1177 - accuracy: 0.5711\n",
            "Epoch 14/52\n",
            "4/4 [==============================] - 4s 952ms/step - loss: 12239.2549 - accuracy: 0.6325\n",
            "Epoch 15/52\n",
            "4/4 [==============================] - 4s 959ms/step - loss: 20950.3418 - accuracy: 0.7211\n",
            "Epoch 16/52\n",
            "4/4 [==============================] - 4s 946ms/step - loss: 29816.9941 - accuracy: 0.5842\n",
            "Epoch 17/52\n",
            "4/4 [==============================] - 4s 935ms/step - loss: 40377.9203 - accuracy: 0.4851\n",
            "Epoch 18/52\n",
            "4/4 [==============================] - 4s 939ms/step - loss: 44218.1203 - accuracy: 0.4491\n",
            "Epoch 19/52\n",
            "4/4 [==============================] - 4s 944ms/step - loss: 50355.0664 - accuracy: 0.5588\n",
            "Epoch 20/52\n",
            "4/4 [==============================] - 4s 935ms/step - loss: 111255.2547 - accuracy: 0.4491\n",
            "Epoch 21/52\n",
            "4/4 [==============================] - 4s 926ms/step - loss: 101544.3266 - accuracy: 0.6132\n",
            "Epoch 22/52\n",
            "4/4 [==============================] - 4s 930ms/step - loss: 201475.5312 - accuracy: 0.6474\n",
            "Epoch 23/52\n",
            "4/4 [==============================] - 4s 928ms/step - loss: 584045.6500 - accuracy: 0.3921\n",
            "Epoch 24/52\n",
            "4/4 [==============================] - 4s 923ms/step - loss: 858862.5875 - accuracy: 0.5035\n",
            "Epoch 25/52\n",
            "4/4 [==============================] - 4s 930ms/step - loss: 1492806.6750 - accuracy: 0.6711\n",
            "Epoch 26/52\n",
            "4/4 [==============================] - 4s 933ms/step - loss: 1056364.5594 - accuracy: 0.6289\n",
            "Epoch 27/52\n",
            "4/4 [==============================] - 4s 938ms/step - loss: 1940652.3500 - accuracy: 0.5307\n",
            "Epoch 28/52\n",
            "4/4 [==============================] - 4s 933ms/step - loss: 1784851.2000 - accuracy: 0.3553\n",
            "Epoch 29/52\n",
            "4/4 [==============================] - 4s 928ms/step - loss: 3824714.9500 - accuracy: 0.3474\n",
            "Epoch 30/52\n",
            "4/4 [==============================] - 4s 937ms/step - loss: 1734852.0625 - accuracy: 0.4351\n",
            "Epoch 31/52\n",
            "4/4 [==============================] - 4s 931ms/step - loss: 3888096.9000 - accuracy: 0.5667\n",
            "Epoch 32/52\n",
            "4/4 [==============================] - 4s 929ms/step - loss: 6382135.3000 - accuracy: 0.4588\n",
            "Epoch 33/52\n",
            "4/4 [==============================] - 4s 936ms/step - loss: 12313527.4000 - accuracy: 0.5675\n",
            "Epoch 34/52\n",
            "4/4 [==============================] - 4s 930ms/step - loss: 11614813.0000 - accuracy: 0.5763\n",
            "Epoch 35/52\n",
            "4/4 [==============================] - 4s 923ms/step - loss: 17023883.7000 - accuracy: 0.6447\n",
            "Epoch 36/52\n",
            "4/4 [==============================] - 4s 929ms/step - loss: 27759893.2000 - accuracy: 0.7351\n",
            "Epoch 37/52\n",
            "4/4 [==============================] - 4s 922ms/step - loss: 38858629.6000 - accuracy: 0.4754\n",
            "Epoch 38/52\n",
            "4/4 [==============================] - 4s 935ms/step - loss: 35848696.8000 - accuracy: 0.5219\n",
            "Epoch 39/52\n",
            "4/4 [==============================] - 4s 934ms/step - loss: 33347659.2000 - accuracy: 0.5246\n",
            "Epoch 40/52\n",
            "4/4 [==============================] - 4s 921ms/step - loss: 61972198.8000 - accuracy: 0.4149\n",
            "Epoch 41/52\n",
            "4/4 [==============================] - 4s 932ms/step - loss: 34240405.6000 - accuracy: 0.6868\n",
            "Epoch 42/52\n",
            "4/4 [==============================] - 4s 928ms/step - loss: 121045528.0000 - accuracy: 0.3711\n",
            "Epoch 43/52\n",
            "4/4 [==============================] - 4s 903ms/step - loss: 70884424.8000 - accuracy: 0.4325\n",
            "Epoch 44/52\n",
            "4/4 [==============================] - 4s 914ms/step - loss: 124795980.8000 - accuracy: 0.5167\n",
            "Epoch 45/52\n",
            "4/4 [==============================] - 4s 912ms/step - loss: 396066150.4000 - accuracy: 0.5561\n",
            "Epoch 46/52\n",
            "4/4 [==============================] - 4s 906ms/step - loss: 488493011.2000 - accuracy: 0.5281\n",
            "Epoch 47/52\n",
            "4/4 [==============================] - 4s 910ms/step - loss: 400455545.6000 - accuracy: 0.5325\n",
            "Epoch 48/52\n",
            "4/4 [==============================] - 4s 908ms/step - loss: 551520358.4000 - accuracy: 0.7860\n",
            "Epoch 49/52\n",
            "4/4 [==============================] - 4s 926ms/step - loss: 909051929.6000 - accuracy: 0.2719\n",
            "Epoch 50/52\n",
            "4/4 [==============================] - 4s 894ms/step - loss: 955924172.8000 - accuracy: 0.7298\n",
            "Epoch 51/52\n",
            "4/4 [==============================] - 4s 884ms/step - loss: 1837401523.2000 - accuracy: 0.2456\n",
            "Epoch 52/52\n",
            "4/4 [==============================] - 4s 891ms/step - loss: 2451051110.4000 - accuracy: 0.8105\n",
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7f65933130e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "3/3 [==============================] - 1s 131ms/step - loss: 2483177216.0000 - accuracy: 0.1184\n",
            "[2483177216.0, 0.1184210553765297]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9l5keRKx795"
      },
      "source": [
        "# fnn input is a 1D array of consumption over the year\n",
        "X1 = [x.flatten() for x in X0]\n",
        "y1 = [meter[1].to_numpy() for meter in meters]\n",
        "\n",
        "# rnn input is a time series between consumption minima and maxima\n",
        "X2 = [np.diff(find_peaks(np.mean(x, axis=1))[0]) for x in X0]\n",
        "y2 = [y != 0 for y in y0]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}